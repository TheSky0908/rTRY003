% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/LVHBA_SVM.R
\name{LVHBA_SVM}
\alias{LVHBA_SVM}
\title{Support Vector Machine Based on LVHBA}
\usage{
LVHBA_SVM(
  features,
  labels,
  K = 3,
  N = 200,
  eta = 0.003,
  alpha = 0.002,
  beta = 0.002,
  gamma1 = 1,
  gamma2 = 1,
  c_0 = 2,
  r = 10,
  ub = 10,
  lb = 10^(-6),
  tol = 1e-06,
  auto_tuning = FALSE,
  temperature = 0.1
)
}
\arguments{
\item{features}{The feature matrix with dimensions n by p, where the j-th column corresponds to the j-th feature.}

\item{labels}{The label vector where the j-th element represents the label of the j-th feature,
with a value of 1 indicating the positive class and -1 indicating the negative class.}

\item{K}{K-fold cross validation.}

\item{N}{Total iterations. Default is 200.}

\item{eta}{Projection stepsize  in LV-HBA of \code{theta,lambda} which is fixed. Default is 0.002.}

\item{alpha}{Projection stepsize in LV-HBA of \code{x,y} which is fixed. Default is 0.002.}

\item{beta}{Projection stepsize in LV-HBA of \code{z} which is fixed. Default is 0.002.}

\item{gamma1}{Proximal parameter in LV-HBA. Default is 1.}

\item{gamma2}{Proximal parameter in LV-HBA. Default is 1.}

\item{c_0}{which is used to generate the penalty parameter \code{c_k} in LV-HBA by \code{c_k = \underline{c}(k+1)^p}.
Default is 2.}

\item{r}{parameter in LV-HBA. Default is 1.}

\item{tol}{Tolerance.}

\item{auto_tuning}{Whether an auto-hyperparameter-tuning is needed.Default is
\code{FALSE}.}

\item{temperature}{Temperature of simulating annealing method for auto-
hyperparameter-tuning. Default is 0.1.}
}
\value{
\item{x}{The optimal hyper-parameters, which is a vector of length (p+1).
The first value is regularization parameter, and the remaining element stands for box constraint \eqn{\bar{w}}}
\item{y}{A vector combines by variables and auxiliary variables of the subproblems.}
\item{w}{A list of t vectors.
The t-th element of the list \code{w} (which is a vector), and the t-th value of c(which is a scalar) represents the variables of the t-th subproblem.}
\item{c}{A vector of t elements.
The t-th element of the list \code{w} (which is a vector), and the t-th value of c(which is a scalar) represents the variables of the t-th subproblem.}
\item{xi}{Auxiliary variable}
\item{theta}{The moreau envelope parameter in MEHA, which is of the same scale as variable y}
\item{Xconv}{Describe the relative convergence situation of sequence x generated by MEHA,
which is computed by \eqn{||x^{k+1}-x^k|| / ||x^K||} based on l2-norm.}
\item{Yconv}{Describe the relative convergence situation of sequence y generated by MEHA,
which is computed by \eqn{||y^{k+1}-y^k|| / ||y^K||} based on l2-norm.}
\item{Thetaconv}{Describe the relative convergence situation of sequence theta generated by MEHA,
which is computed by \eqn{||theta^{k+1}-theta^k|| / ||theta^K||} based on l2-norm.}
\item{Fseq}{The upper function value sequence generated by the iteration based on validation set.}
}
\description{
This R function is written to solve the hyperparameter tuning problem of Support Vector Machines (SVM) using the LV-HBA algorithm,
please refer to the listed literature for the specific algorithm and model.It should be noted that in order to successfully apply the algorithm,
the upper objective function is smoothed using softplus function approximation,
and the lower problem is smoothed by introducing auxiliary variables and additional constraints.
}
\references{
Yao, W., Yu, C., Zeng, S., & Zhang, J. (2024).
"Constrained Bi-Level Optimization: Proximal Lagrangian Value Function Approach and Hessian-free Algorithm."
Available at: https://openreview.net/forum?id=xJ5N8qrEPl

\if{html}{\out{<div class="sourceCode">}}\preformatted{Gao, L., Ye, J. J., Yin, H., Zeng, S., & Zhang, J. (2022).
"Value function based difference-of-convex algorithm for bilevel hyperparameter selection problems."
Available at: https://proceedings.mlr.press/v162/gao22j.html
}\if{html}{\out{</div>}}
}
