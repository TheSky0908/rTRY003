% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/MEHA_ElasticNet.R
\name{MEHA_Elasticnet}
\alias{MEHA_Elasticnet}
\title{Elastic Net Based on MEHA}
\usage{
MEHA_Elasticnet(
  A_val,
  b_val,
  A_tr,
  b_tr,
  N = 500,
  alpha = 0.001,
  beta = 1e-05,
  eta = 1e-05,
  gamma = 2,
  c = 2,
  p = 0.48,
  auto_tuning = FALSE,
  temperature = 0.1
)
}
\arguments{
\item{A_val}{Input feature matrix of validation set, of dimension n by p,
where n is the total number of validation samples and p is feature number.
Hence, each row is an observation vector.}

\item{b_val}{Quantitative response variable of validation set.}

\item{A_tr}{Input feature matrix of training set, of dimension n' by p,
where n' is the total number of training samples and p is feature number.}

\item{b_tr}{Quantitative response variable of training set.}

\item{N}{Total iterations. Default is 500.}

\item{alpha}{Default is 0.001.}

\item{beta}{Default is 1e-5.}

\item{eta}{Default is 1e-5.}

\item{gamma}{Default is 2.}

\item{c}{Default is 2.}

\item{p}{Default is 0.48.}

\item{auto_tuning}{Whether an auto-hyperparameter-tuning is needed.
Default is \code{FALSE}.}

\item{temperature}{Temperature of simulating annealing method for auto-
hyperparameter-tuning. Default is 0.1.}
}
\value{
a list with 7 components:
\describe{
\item{x}{to}
\item{y}{Coefficients}
\item{theta}{to}
\item{Xconv}{The convergence of sequence X}
\item{Yconv}{The convergence of sequence Y}
\item{Thetaconv}{The convergence of sequence theta}
\item{Fseq}{The convergence of upper function}
}
}
\description{
\if{html}{\out{<div class="sourceCode">}}\preformatted{Elastic Net combines the penalties of Lasso (L1 regularization) and Ridge
(L2 regularization) methods. This approach is beneficial when there are
multiple correlated predictors. By balancing the L1 and L2 penalties,
Elastic Net encourages both sparsity (like Lasso) and grouping of
correlated variables (like Ridge). The model introduces two hyperparameters:
alpha (α), which controls the mix between Lasso and Ridge, and lambda (λ),
which determines the overall strength of regularization.
This function is to ......
}\if{html}{\out{</div>}}
}
